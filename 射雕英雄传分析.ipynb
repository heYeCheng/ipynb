{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feyman\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import jieba\n",
    "import re\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = 'wsy0929sky@formail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile('\\w+@\\w+\\.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = '444relearn555@163.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = re.match(pattern,ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'444relearn555@163.com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('foo','seafood').group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = re.match('foo','seafood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'car', 'car']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('car','tcarr carry a car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \"你好世界1024，今天天气不错\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你', '世', '界1024', '，', '今', '气', '不']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[^好天错]\\d*',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好世界1024，今天天气不错'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"你好\\w+，\\w+\",s).group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = open(\"C:/Users/feyman/Desktop/test/test.txt\",encoding=\"utf-8\",errors=\"ignore\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    data_filter = filter(lambda s :len(s)>= 5,data)\n",
    "    m1 = map(lambda s : s.strip(\"\\u3000\\u3000|\\n\"),data_filter)\n",
    "    m2 = map(lambda s : s.replace(\"\\u3000\",\"\"),m1)\n",
    "    cut_words = map(lambda s : list(jieba.cut(s)),m2)\n",
    "    return list(cut_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2017-03-04 10:18:44,513 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\feyman\\AppData\\Local\\Temp\\jieba.cache\n",
      "2017-03-04 10:18:44,517 : DEBUG : Loading model from cache C:\\Users\\feyman\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.782 seconds.\n",
      "2017-03-04 10:18:45,296 : DEBUG : Loading model cost 0.782 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-03-04 10:18:45,298 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "cut_words = process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['郭啸天',\n",
       " '带',\n",
       " '着',\n",
       " '张十五',\n",
       " '来到',\n",
       " '村头',\n",
       " '一家',\n",
       " '小',\n",
       " '酒店',\n",
       " '中',\n",
       " '，',\n",
       " '在',\n",
       " '张板',\n",
       " '桌旁',\n",
       " '坐',\n",
       " '了',\n",
       " '。']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_words[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_wordls = []\n",
    "for each in cut_words:\n",
    "    total_wordls.extend(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = np.unique(total_wordls,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = pd.Series(data = n[1],index = n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "，        66689\n",
       "。        22383\n",
       "“        12054\n",
       "”        11981\n",
       "的        11867\n",
       "：        11161\n",
       "了        10971\n",
       "他         7261\n",
       "是         6541\n",
       "道         5831\n",
       "我         5580\n",
       "你         5382\n",
       "在         5257\n",
       "？         4874\n",
       "也         3229\n",
       "这         2891\n",
       "又         2763\n",
       "她         2718\n",
       "郭靖        2613\n",
       "那         2359\n",
       "不         2350\n",
       "得         2295\n",
       "去         2063\n",
       "、         2059\n",
       "说         2018\n",
       "！         1885\n",
       "却         1783\n",
       "黄蓉        1751\n",
       "着         1719\n",
       "来         1701\n",
       "         ...  \n",
       "左军右          1\n",
       "左冲           1\n",
       "石是           1\n",
       "高深莫测         1\n",
       "左右两          1\n",
       "工乎           1\n",
       "工            1\n",
       "巢穴           1\n",
       "石级           1\n",
       "石鼓           1\n",
       "嵘            1\n",
       "嵩山少林寺        1\n",
       "石面           1\n",
       "石门           1\n",
       "巍            1\n",
       "巍乎           1\n",
       "巍峨           1\n",
       "巍巍           1\n",
       "川            1\n",
       "巡酒           1\n",
       "川湘           1\n",
       "石米           1\n",
       "州府           1\n",
       "巡            1\n",
       "巡到           1\n",
       "巡查           1\n",
       "巡海           1\n",
       "石穴           1\n",
       "石础           1\n",
       "ｍ            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-04 11:23:10,190 : INFO : collecting all words and their counts\n",
      "2017-03-04 11:23:10,190 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-03-04 11:23:10,303 : INFO : collected 47227 word types from a corpus of 596351 raw words and 2690 sentences\n",
      "2017-03-04 11:23:10,303 : INFO : Loading a fresh vocabulary\n",
      "2017-03-04 11:23:10,337 : INFO : min_count=20 retains 2827 unique words (5% of original 47227, drops 44400)\n",
      "2017-03-04 11:23:10,338 : INFO : min_count=20 leaves 473119 word corpus (79% of original 596351, drops 123232)\n",
      "2017-03-04 11:23:10,347 : INFO : deleting the raw counts dictionary of 47227 items\n",
      "2017-03-04 11:23:10,350 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2017-03-04 11:23:10,351 : INFO : downsampling leaves estimated 309155 word corpus (65.3% of prior 473119)\n",
      "2017-03-04 11:23:10,351 : INFO : estimated required memory for 2827 words and 100 dimensions: 3675100 bytes\n",
      "2017-03-04 11:23:10,360 : INFO : resetting layer weights\n",
      "2017-03-04 11:23:10,400 : INFO : training model with 3 workers on 2827 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-03-04 11:23:10,400 : INFO : expecting 2690 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-03-04 11:23:11,405 : INFO : PROGRESS: at 98.48% examples, 1522311 words/s, in_qsize 5, out_qsize 0\n",
      "2017-03-04 11:23:11,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-03-04 11:23:11,412 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-03-04 11:23:11,417 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-03-04 11:23:11,418 : INFO : training on 2981755 raw words (1544417 effective words) took 1.0s, 1521344 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(cut_words,min_count=20,sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38366935,  0.46981919, -0.0043413 , -0.26211476,  0.13916188,\n",
       "        0.0812159 , -0.02952697,  0.02885012,  0.11774399, -0.13236122,\n",
       "        0.12843326,  0.08886866, -0.12320778,  0.15950419, -0.07332431,\n",
       "       -0.20144033, -0.21999463, -0.00957063, -0.21256846,  0.08037788,\n",
       "        0.17832898,  0.07347424, -0.12112255, -0.33940718,  0.26528278,\n",
       "        0.0851805 ,  0.2152352 ,  0.343986  ,  0.0933392 , -0.29680395,\n",
       "        0.03762637,  0.08420643,  0.29203767, -0.10801614,  0.20233688,\n",
       "       -0.17992368, -0.35428244,  0.65755826,  0.09381723, -0.1169819 ,\n",
       "        0.04065146,  0.03031288, -0.01129615,  0.03125716,  0.12051398,\n",
       "       -0.19937795, -0.15131886,  0.13661133, -0.26767501,  0.03965162,\n",
       "       -0.02729095,  0.29999363,  0.12036122,  0.23151731,  0.13966666,\n",
       "        0.23936529,  0.02636108, -0.00167438,  0.1351632 ,  0.39420563,\n",
       "        0.12923563, -0.00577859, -0.17456061, -0.18169335,  0.01880411,\n",
       "        0.02198375, -0.12736766, -0.386657  , -0.24465211, -0.02580499,\n",
       "       -0.01619437, -0.08681406, -0.39534819, -0.06282111, -0.31974822,\n",
       "        0.08315592,  0.2392163 ,  0.06460159, -0.31577981,  0.42449099,\n",
       "        0.23669483, -0.02953473,  0.02401319,  0.22473945, -0.03047296,\n",
       "       -0.36371347, -0.089524  ,  0.01664675,  0.06145061, -0.08493181,\n",
       "        0.04492591, -0.11934977,  0.10890262, -0.24244182, -0.04151085,\n",
       "       -0.12791155,  0.07149512, -0.1441849 , -0.12635702,  0.35231838], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"郭靖\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-04 11:23:15,014 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('黄蓉', 0.9441424608230591),\n",
       " ('欧阳克', 0.9082238674163818),\n",
       " ('欧阳锋', 0.8996136784553528),\n",
       " ('梅超风', 0.8222911357879639),\n",
       " ('穆念慈', 0.8043638467788696),\n",
       " ('一眼', 0.8032893538475037),\n",
       " ('黄药师', 0.7945334315299988),\n",
       " ('裘千仞', 0.7937788963317871),\n",
       " ('洪七公', 0.7926408052444458),\n",
       " ('一惊', 0.7855643630027771),\n",
       " ('陆冠英', 0.7809769511222839),\n",
       " ('程瑶迦', 0.7791975140571594),\n",
       " ('当下', 0.777950644493103),\n",
       " ('那公子', 0.7761392593383789),\n",
       " ('众人', 0.7567017674446106),\n",
       " ('完颜康', 0.7546082735061646),\n",
       " ('梁子翁', 0.7538256049156189),\n",
       " ('渔人', 0.7519704699516296),\n",
       " ('回头', 0.7493696808815002),\n",
       " ('柯镇恶', 0.7446933388710022)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['郭靖'],topn=20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
